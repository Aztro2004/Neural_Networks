{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa986760-03f2-4945-bae8-3a537882974c",
   "metadata": {},
   "source": [
    "# Clasificador de animales\n",
    "## Diego Maldonado Castro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad14b863-bb88-4d1a-b6fa-b2461c0d3e47",
   "metadata": {},
   "source": [
    "### Importamos librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269d0d91-d95c-473f-afd3-34619e492c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddeee47-0bfe-4720-abe9-69804b7320c8",
   "metadata": {},
   "source": [
    "A falta de soporte de fast.ai para Mac vamos a declarar la clase para nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d34b7dc-6cd8-40b1-8300-68ea2c542b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.label_mapping = {label: idx for idx, label in enumerate(self.annotations['Animal'].unique())}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.annotations.iloc[idx, 0]  # nombre de img.\n",
    "        img_path = os.path.join(self.root_dir, img_name)  # unir nombres de img.\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        label = self.annotations.iloc[idx, 1]  # etiquetas\n",
    "\n",
    "        label = self.label_mapping.get(label, -1)\n",
    "\n",
    "        image = self.transform(image) if self.transform else transforms.ToTensor()(image)\n",
    "        label = torch.tensor(label)  # label a tensor\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ed9a0a-088f-448d-ae19-e33380b0c4ea",
   "metadata": {},
   "source": [
    "Aplicamos una transformación simple a las imágenes y cargamos nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd96e48-46d2-4654-91c9-90d2209fc4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "csv_file = './AnimalsSmall/train.csv'  # CSV \n",
    "root_dir = './AnimalsSmall/images'     # img. \n",
    "\n",
    "custom_dataset = CustomImageDataset(csv_file=csv_file, root_dir=root_dir, transform=transform);len(custom_dataset) #number of img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434a6779-dddb-4bc6-b2a0-ed222d4079ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128]) tensor(5)\n"
     ]
    }
   ],
   "source": [
    "image, label = custom_dataset[5] #Checando el tamaño de los tensores\n",
    "print(image.shape,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed01511-e430-47b0-88f9-90914fff6016",
   "metadata": {},
   "source": [
    "Declaramos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37afa569-2704-4e9a-af70-ece5669c35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.BatchNorm2d(3),\n",
    "    nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 30), # 30 clases de animales\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e7330f-6e72-45a8-90e9-d4ad9961a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, weight_decay=1e-5) # Optimizador Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6868a5b-1156-4787-b9ed-ec85faa1c139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (2): ReLU()\n",
       "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (6): ReLU()\n",
       "  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (9): ReLU()\n",
       "  (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (12): AdaptiveAvgPool2d(output_size=1)\n",
       "  (13): Flatten(start_dim=1, end_dim=-1)\n",
       "  (14): Linear(in_features=128, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 20 \n",
    "device = torch.device('mps') # para Mac se usa mps\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60d446f6-6e82-44da-9f91-a70811c91646",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9bfcd5-8c8c-4244-bef0-b011e0a91b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d3135-9a69-41b1-acf7-700e403b1934",
   "metadata": {},
   "source": [
    "Creando el conjunto de entrenamiento, validación y entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbfa7bd8-5a79-4ee4-ac49-bee631405ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 3.1006\n",
      "Epoch 1/20, Evaluation Loss: 2.9347, Evaluation Accuracy: 18.88%\n",
      "Epoch 2/20, Training Loss: 2.8581\n",
      "Epoch 2/20, Evaluation Loss: 2.7892, Evaluation Accuracy: 22.04%\n",
      "Epoch 3/20, Training Loss: 2.7173\n",
      "Epoch 3/20, Evaluation Loss: 2.7088, Evaluation Accuracy: 23.73%\n",
      "Epoch 4/20, Training Loss: 2.6387\n",
      "Epoch 4/20, Evaluation Loss: 2.6728, Evaluation Accuracy: 25.04%\n",
      "Epoch 5/20, Training Loss: 2.5927\n",
      "Epoch 5/20, Evaluation Loss: 2.5905, Evaluation Accuracy: 25.85%\n",
      "Epoch 6/20, Training Loss: 2.5581\n",
      "Epoch 6/20, Evaluation Loss: 2.6005, Evaluation Accuracy: 25.96%\n",
      "Epoch 7/20, Training Loss: 2.5098\n",
      "Epoch 7/20, Evaluation Loss: 2.5098, Evaluation Accuracy: 28.96%\n",
      "Epoch 8/20, Training Loss: 2.4777\n",
      "Epoch 8/20, Evaluation Loss: 2.5030, Evaluation Accuracy: 28.46%\n",
      "Epoch 9/20, Training Loss: 2.4493\n",
      "Epoch 9/20, Evaluation Loss: 2.4507, Evaluation Accuracy: 30.15%\n",
      "Epoch 10/20, Training Loss: 2.4099\n",
      "Epoch 10/20, Evaluation Loss: 2.4103, Evaluation Accuracy: 31.23%\n",
      "Epoch 11/20, Training Loss: 2.3897\n",
      "Epoch 11/20, Evaluation Loss: 2.4440, Evaluation Accuracy: 31.15%\n",
      "Epoch 12/20, Training Loss: 2.3612\n",
      "Epoch 12/20, Evaluation Loss: 2.4015, Evaluation Accuracy: 31.12%\n",
      "Epoch 13/20, Training Loss: 2.3441\n",
      "Epoch 13/20, Evaluation Loss: 2.3896, Evaluation Accuracy: 31.85%\n",
      "Epoch 14/20, Training Loss: 2.3250\n",
      "Epoch 14/20, Evaluation Loss: 2.3509, Evaluation Accuracy: 34.08%\n",
      "Epoch 15/20, Training Loss: 2.2912\n",
      "Epoch 15/20, Evaluation Loss: 2.3465, Evaluation Accuracy: 32.88%\n",
      "Epoch 16/20, Training Loss: 2.2896\n",
      "Epoch 16/20, Evaluation Loss: 2.3416, Evaluation Accuracy: 32.65%\n",
      "Epoch 17/20, Training Loss: 2.2761\n",
      "Epoch 17/20, Evaluation Loss: 2.3626, Evaluation Accuracy: 32.65%\n",
      "Epoch 18/20, Training Loss: 2.2532\n",
      "Epoch 18/20, Evaluation Loss: 2.3154, Evaluation Accuracy: 33.65%\n",
      "Epoch 19/20, Training Loss: 2.2264\n",
      "Epoch 19/20, Evaluation Loss: 2.3003, Evaluation Accuracy: 35.35%\n",
      "Epoch 20/20, Training Loss: 2.2341\n",
      "Epoch 20/20, Evaluation Loss: 2.2674, Evaluation Accuracy: 34.65%\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "train_subset_size = int(0.8 * dataset_size)  \n",
    "eval_subset_size = dataset_size - train_subset_size\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:train_subset_size]\n",
    "eval_indices = indices[train_subset_size:]\n",
    "\n",
    "train_subset = Subset(custom_dataset, train_indices)\n",
    "eval_subset = Subset(custom_dataset, eval_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=16, shuffle=True)\n",
    "eval_loader = DataLoader(eval_subset, batch_size=13, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Evaluacion\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in eval_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    eval_loss /= len(eval_loader.dataset)\n",
    "    eval_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Evaluation Loss: {eval_loss:.4f}, Evaluation Accuracy: {eval_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092aa13d-62ea-47ad-915b-6fb25c4d8edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
